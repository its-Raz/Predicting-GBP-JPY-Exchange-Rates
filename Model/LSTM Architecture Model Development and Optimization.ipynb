{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba82f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "\n",
    "def get_statistics(train_df, val_df, test_df, target_column='Close'):\n",
    "    \"\"\"\n",
    "    Calculate and print statistical information for the train, validation, and test DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df: DataFrame containing the training data.\n",
    "    - val_df: DataFrame containing the validation data.\n",
    "    - test_df: DataFrame containing the test data.\n",
    "    - target_column: The column name of the target variable to calculate statistics for (default is 'Close').\n",
    "    \"\"\"\n",
    "    # Function to print statistics for a given DataFrame\n",
    "    def print_statistics(df, name):\n",
    "        print(f\"\\nStatistics for {name} DataFrame:\")\n",
    "        print(f\"Mean: {df[target_column].mean()}\")\n",
    "        print(f\"Variance: {df[target_column].var()}\")\n",
    "        print(f\"Standard Deviation: {df[target_column].std()}\")\n",
    "        print(f\"Minimum: {df[target_column].min()}\")\n",
    "        print(f\"Maximum: {df[target_column].max()}\")\n",
    "        print(f\"25th Percentile: {df[target_column].quantile(0.25)}\")\n",
    "        print(f\"Median: {df[target_column].median()}\")\n",
    "        print(f\"75th Percentile: {df[target_column].quantile(0.75)}\")\n",
    "#         print(\"\\nDescriptive Statistics:\\n\", df.describe())\n",
    "\n",
    "    # Print statistics for each DataFrame\n",
    "    print_statistics(train_df, \"Training\")\n",
    "    print_statistics(val_df, \"Validation\")\n",
    "    print_statistics(test_df, \"Test\")\n",
    "\n",
    "\n",
    "def plot_close(train_df, val_df, test_df, target_column='Close',xlim_start=None):\n",
    "    \"\"\"\n",
    "    Plots the 'Close' column from the train, validation, and test DataFrames, with different colors for each set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df: DataFrame containing the training data.\n",
    "    - val_df: DataFrame containing the validation data.\n",
    "    - test_df: DataFrame containing the test data.\n",
    "    - target_column: The column name of the target variable to plot (default is 'Close').\n",
    "    \"\"\"\n",
    "    # Ensure the index is a datetime type\n",
    "    train_df.index = pd.to_datetime(train_df.index)\n",
    "    val_df.index = pd.to_datetime(val_df.index)\n",
    "    test_df.index = pd.to_datetime(test_df.index)\n",
    "\n",
    "    # Convert target_column to numeric, if necessary\n",
    "    train_df[target_column] = pd.to_numeric(train_df[target_column], errors='coerce')\n",
    "    val_df[target_column] = pd.to_numeric(val_df[target_column], errors='coerce')\n",
    "    test_df[target_column] = pd.to_numeric(test_df[target_column], errors='coerce')\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot the training set\n",
    "    plt.plot(train_df.index, train_df[target_column], label='Train', color='blue')\n",
    "\n",
    "    # Plot the validation set\n",
    "    plt.plot(val_df.index, val_df[target_column], label='Validation', color='orange')\n",
    "\n",
    "    # Plot the test set\n",
    "    plt.plot(test_df.index, test_df[target_column], label='Test', color='green')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f'{target_column} over Time for Train, Validation, and Test Sets')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(target_column)\n",
    "\n",
    "    # Concatenate the index objects into a single Series for setting ticks\n",
    "    all_dates = pd.Series(train_df.index.append(val_df.index).append(test_df.index))\n",
    "    unique_months = all_dates.dt.to_period('M').unique()  # Get unique months\n",
    "\n",
    "    # Set major ticks to the unique months in the dataset\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))  # Set major ticks to every 6 months\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))  # Format ticks as Year-Month\n",
    "\n",
    "    # Set x-axis limits to the provided values, or default to the range of the data\n",
    "    if xlim_start is not None and xlim_end is not None:\n",
    "        plt.xlim(pd.to_datetime(xlim_start), pd.to_datetime(xlim_end))\n",
    "    else:\n",
    "        plt.xlim(train_df.index.min(), test_df.index.max())\n",
    "\n",
    "    # Add a legend to differentiate the sets\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Function to split the time series data into train, validation, and test sets\n",
    "def split_time_series(df, train_size=0.86, val_size=0.09):\n",
    "    train_end = int(len(df) * train_size)\n",
    "    val_end = int(len(df) * (train_size + val_size))\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end:val_end]\n",
    "    test_df = df[val_end:]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "# Prepare sequences for LSTM\n",
    "def prepare_sequences(df: pd.DataFrame, target_column=\"Close\", sequence_length=30):\n",
    "    feature_columns = df.columns[df.columns != target_column]\n",
    "    features = df[feature_columns].values\n",
    "    target = df[target_column].values\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        end_ix = i + sequence_length\n",
    "        X.append(features[i:end_ix])\n",
    "        y.append(target[end_ix])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_data_for_predictions(train_df, validation_df, test_df, n_lags=50, target_column='Close'):\n",
    "    \"\"\"\n",
    "    Prepares data for making predictions on the test set starting from day 1 using the last samples \n",
    "    from the validation set to create the lagged features.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df: DataFrame containing the training data.\n",
    "    - validation_df: DataFrame containing the validation data.\n",
    "    - test_df: DataFrame containing the test data (to predict on).\n",
    "    - n_lags: Number of lagged time steps to use as features.\n",
    "    - target_column: The column name of the target variable.\n",
    "\n",
    "    Returns:\n",
    "    - X_test: Numpy array containing the lagged features for prediction.\n",
    "    \"\"\"\n",
    "    # Drop target column and ensure no NaNs in the validation and test data\n",
    "    validation_df = validation_df.dropna().drop(columns=[target_column])\n",
    "    test_df = test_df.dropna().drop(columns=[target_column])\n",
    "\n",
    "    # Take the last n_lags rows from the validation data to start creating lagged features for test\n",
    "    if len(validation_df) < n_lags:\n",
    "        raise ValueError(f\"Not enough validation data for lagging: {len(validation_df)} found, but {n_lags} required.\")\n",
    "\n",
    "    # Initialize the historical data with the last n_lags rows from validation data\n",
    "    historical_data = validation_df[-n_lags:].copy()\n",
    "\n",
    "    # Initialize a list to store lagged features for X_test\n",
    "    X_test = []\n",
    "\n",
    "    # Create lagged features for the test data\n",
    "    for i in range(len(test_df)):\n",
    "        if i == 0:\n",
    "            # For the first test day, use the last n_lags from validation\n",
    "            window_data = historical_data\n",
    "        else:\n",
    "            # For subsequent test days, use a sliding window of the available test data\n",
    "            window_data = pd.concat([historical_data, test_df.iloc[:i]]).iloc[-n_lags:]\n",
    "\n",
    "        # Append the lagged features for the current test day\n",
    "        X_test.append(window_data.values)\n",
    "        \n",
    "        # Update the historical data by appending the current test day\n",
    "        historical_data = pd.concat([historical_data, test_df.iloc[[i]]])\n",
    "\n",
    "    # Convert the list of lagged features to a NumPy array\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    # Verify that X_test contains no NaN values\n",
    "    if np.any(np.isnan(X_test)):\n",
    "        raise ValueError(\"X_test contains NaN values.\")\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "\n",
    "def predict_future_prices(model, last_sequence, n_days=7):\n",
    "    future_prices = []\n",
    "\n",
    "    # Use the last known sequence to predict future values\n",
    "    current_sequence = last_sequence.copy()\n",
    "\n",
    "    for _ in range(n_days):\n",
    "        # Make a prediction\n",
    "        next_price = model.predict(current_sequence[np.newaxis, :, :])\n",
    "        future_prices.append(next_price[0, 0])\n",
    "        \n",
    "        # Update the current sequence with the predicted price\n",
    "        # Shift the sequence to the left and add the new prediction at the end\n",
    "        current_sequence = np.roll(current_sequence, -1, axis=0)\n",
    "        current_sequence[-1, -1] = next_price  # Replace the last feature with the predicted price\n",
    "    \n",
    "    return future_prices\n",
    "\n",
    "\n",
    "# Function to build and compile the LSTM model\n",
    "def build_and_compile_model(input_shape, hidden_dims, dense_units, dropout_rate, lr):\n",
    "    model = Sequential()\n",
    "    num_layers = len(hidden_dims)\n",
    "    for i in range(num_layers):\n",
    "        model.add(LSTM(hidden_dims[i], return_sequences=True if i < num_layers - 1 else False, input_shape=input_shape))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    for dense_unit in dense_units:\n",
    "        model.add(Dense(dense_unit, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Function to save results and plots\n",
    "def save_results_and_plots(history, model_name, model_dir):\n",
    "    # Save training history\n",
    "#     history_df = pd.DataFrame(history.history)\n",
    "#     history_df.to_excel(os.path.join(model_dir, f'{model_name}_history.xlsx'), index=False)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(model_dir, f'{model_name}_loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Function to save predictions plot\n",
    "def save_predictions_plot(y_true, y_pred, dates, model_name, model_dir, prediction_type):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(dates, y_true, label='Actual Values', color='blue', marker='o')\n",
    "    plt.plot(dates, y_pred, label='Predicted Values', color='orange', marker='x')\n",
    "\n",
    "    # Formatting the x-axis\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=1))\n",
    "\n",
    "    # Adding titles and labels\n",
    "    plt.title(f'{model_name} - {prediction_type} - Predictions vs Actual Values')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Values')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(model_dir, f'{model_name}_{prediction_type}_predictions_plot.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305992ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code starts here\n",
    "print('starting...')\n",
    "df = pd.read_csv(r\"transformed_data.csv\")\n",
    "df = df.iloc[: -220]\n",
    "df = df.set_index('index')\n",
    "df.dropna(inplace = True)\n",
    "print('data loaded')\n",
    "# Split the data into train, validation, and test sets\n",
    "train_df,val_df,  test_df = split_time_series(df)\n",
    "\n",
    "# Apply Standard Scaling to each set\n",
    "scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "X_train = train_df.drop('Close', axis = 1)\n",
    "y_train = train_df['Close']\n",
    "\n",
    "X_val = val_df.drop('Close', axis = 1)\n",
    "y_val = val_df['Close']\n",
    "\n",
    "\n",
    "X_test = test_df.drop('Close', axis = 1)\n",
    "y_test = test_df['Close']\n",
    "\n",
    "train_target_scaled = target_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "val_target_scaled = target_scaler.transform(y_val.values.reshape(-1,1))\n",
    "test_target_scaled = target_scaler.transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "train_scaled = scaler.fit_transform(train_df)\n",
    "val_scaled = scaler.transform(val_df)\n",
    "test_scaled =  scaler.transform(test_df)\n",
    "\n",
    "# Convert scaled arrays back to DataFrame with original indices and columns\n",
    "train_scaled_df = pd.DataFrame(train_scaled, columns= df.columns, index=train_df.index)\n",
    "val_scaled_df = pd.DataFrame(val_scaled, columns= df.columns, index=val_df.index)\n",
    "test_scaled_df = pd.DataFrame(test_scaled, columns= df.columns, index=test_df.index)\n",
    "\n",
    "# Preparing sequences for training and validation data\n",
    "sequence_length = 50\n",
    "num_features = 50  # Number of features\n",
    "\n",
    "X_train, y_train = prepare_sequences(train_scaled_df, target_column=\"Close\", sequence_length=sequence_length)\n",
    "X_val, y_val = prepare_sequences(val_scaled_df, target_column=\"Close\", sequence_length=sequence_length)\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (sequence_length, number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_time_series(df)\n",
    "plot_close(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming you have already split your dataset into train_df, val_df, and test_df\n",
    "get_statistics(train_df, val_df, test_df, target_column='Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46add103",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'hidden_dims': [\n",
    "        [128, 64],            # A common starting point with two layers\n",
    "        [256, 128],           # Slightly larger architecture for increased capacity\n",
    "        [128],                # Simple architecture for baseline comparison\n",
    "        [512, 256],           # Larger model for capturing complex patterns\n",
    "        [256, 128, 64],       # Three-layer architecture for capturing interactions\n",
    "        [256, 256],           # Two large layers for deeper learning\n",
    "        [128, 64, 32, 16],    # More layers with decreasing size for capturing nuances\n",
    "        [128, 128],           # Two equal-sized layers for balanced capacity\n",
    "        [512, 256, 128],      # A deeper stack with a significant capacity\n",
    "        [128, 64, 64],        # Wider layers for more feature learning\n",
    "        [256, 128, 64, 32]    # Complex model with a diverse structure\n",
    "    ],\n",
    "    'dense_units': [\n",
    "        [64, 32, 16], # Smaller layers for basic configurations\n",
    "        [128, 64],            # Balanced dense layers\n",
    "        [256, 128],           # Larger dense layers for improved learning\n",
    "        [64, 32],             # Smaller layers to test overfitting\n",
    "        [128, 128],           # Two equal-sized layers\n",
    "        [64, 64, 32],         # Three-layer structure for capturing interactions\n",
    "        [256, 128, 64],       # Larger dense layers to explore complex interactions\n",
    "        [128, 32, 16],        # Simpler setup with a clear decline\n",
    "        [128, 64, 32, 16],    # Deeper architecture with declining size\n",
    "        [128, 64, 64],        # Slightly wider layers with an added layer            \n",
    "        [128, 32]             # A basic two-layer configuration\n",
    "    ],\n",
    "    'dropout_rate': [0.1, 0.2, 0.25, 0.3, 0.5],  # Start with lower rates for complex models\n",
    "    'lr': [1e-3, 1e-4, 1e-5],    # Moderate learning rates to start, with room for adjustment\n",
    "    'batch_size': [4, 8, 16, 32, 64],  # Mid-sized batch to start, adjusting downwards and upwards\n",
    "    'epochs': [100, 200]  # Aiming for a balance between training time and model convergence\n",
    "}\n",
    "\n",
    "# Directory to save models\n",
    "model_dir = 'models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Model Name', 'Test Loss'])\n",
    "\n",
    "# results_df = pd.read_excel(r\"results_summary.xlsx\")\n",
    "\n",
    "counter = 1\n",
    "# Loop through all combinations of hyperparameters\n",
    "for params in product(*hyperparams.values()):\n",
    "    hidden_dims, dense_units, dropout_rate, lr, batch_size, epochs = params\n",
    "\n",
    "        \n",
    "    # Build the model\n",
    "    model = build_and_compile_model(input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                                    hidden_dims=hidden_dims,\n",
    "                                    dense_units=dense_units,\n",
    "                                    dropout_rate=dropout_rate,\n",
    "                                    lr=lr\n",
    "                                   )\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights = True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        callbacks=[early_stopping],shuffle=False)\n",
    "    \n",
    "    # Save the model\n",
    "    model_name = f'model_{counter}_hidden_dims_{str(hidden_dims).replace(\", \", \"_\")}_dense_units_{str(dense_units).replace(\", \", \"_\")}_dropout_{dropout_rate}_lr_{lr}_batch_{batch_size}_epochs_{epochs}'\n",
    "    model.save(os.path.join(model_dir, f'{model_name}.h5'))\n",
    "    counter+=1\n",
    "    # Save results and plots\n",
    "    save_results_and_plots(history, model_name, model_dir)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    \n",
    "    val_mse = mean_squared_error(target_scaler.inverse_transform(y_val.reshape(-1,1)),\n",
    "                                 target_scaler.inverse_transform(y_val_pred.reshape(-1,1)))\n",
    "    print(\"Validation MSE:\", val_mse)\n",
    "\n",
    "    # Save predictions plot for validation set\n",
    "    future_days = 30\n",
    "    dates = pd.date_range(start=val_df.index[0], periods=future_days)\n",
    "    save_predictions_plot(target_scaler.inverse_transform(y_val[:future_days].reshape(-1,1)),\n",
    "                          target_scaler.inverse_transform(y_val_pred[:future_days].reshape(-1,1)), dates, model_name, model_dir, 'Validation')\n",
    "\n",
    "    # Calculate Mean Squared Error for validation set target_scaler.inverse_transform()\n",
    "    mse_val = mean_squared_error(target_scaler.inverse_transform(y_val.reshape(-1,1)),\n",
    "                                 target_scaler.inverse_transform(y_val_pred.reshape(-1,1)))\n",
    "    \n",
    "    # Prepare for test predictions\n",
    "    prediction_days = 80\n",
    "    start_index = len(val_df) - sequence_length\n",
    "    preds_val = pd.DataFrame(target_scaler.inverse_transform(y_val_pred), columns=['Prediction_val'], index= val_df.iloc[-start_index:].index)\n",
    "\n",
    "    validation_valuations = pd.DataFrame(index = preds_val.iloc[:prediction_days].index)\n",
    "    \n",
    "    validation_valuations['Prediction'] = preds_val['Prediction_val'][:prediction_days] \n",
    "    validation_valuations['Close'] = target_scaler.inverse_transform(y_val[:prediction_days].reshape(-1,1))\n",
    "\n",
    "    # Save validation valuations MSE\n",
    "    mse_val_week = mean_squared_error(validation_valuations['Close'],\n",
    "                                     validation_valuations['Prediction'])\n",
    "    \n",
    "    # Save validation valuations MSE\n",
    "    mae_val_week = mean_absolute_error(validation_valuations['Close'],\n",
    "                                     validation_valuations['Prediction'])\n",
    "    \n",
    "    print(f'Mean Squared Error for Validation Predictions: {mse_val_week}')\n",
    "    \n",
    "    # Test plotting\n",
    "    X_test = prepare_data_for_predictions(train_df, val_df,test_df,n_lags = sequence_length)  # Adjusted to return only X_test\n",
    "\n",
    "    prediction_days = 80\n",
    "\n",
    "    predictions_test = model.predict(X_test)\n",
    "    preds = pd.DataFrame(target_scaler.inverse_transform(predictions_test),columns=['Prediction'], index = test_df.index)\n",
    "    real_test_values = test_df['Close']\n",
    "\n",
    "    test_valuations = pd.DataFrame(index = test_df.index[:prediction_days])\n",
    "    test_valuations['Prediction'] = preds[:prediction_days]\n",
    "    test_valuations['Close'] = real_test_values[:prediction_days]\n",
    "\n",
    "    # Calculate Mean Squared Error\n",
    "    mse_test = mean_squared_error(test_valuations['Close'], test_valuations['Prediction'])\n",
    "    \n",
    "    mae_test = mean_absolute_error(test_valuations['Close'], test_valuations['Prediction'])\n",
    "    \n",
    "    print(f'Mean Squared Error for Test Predictions: {mse_test}')\n",
    "    \n",
    "    save_predictions_plot(y_test[:future_days], target_scaler.inverse_transform(predictions_test[:future_days]), dates, model_name, model_dir, 'Test Set')\n",
    "\n",
    "    # Save validation valuations MSE\n",
    "    mse_test_month = mean_squared_error(test_valuations['Close'],\n",
    "                                      test_valuations['Prediction'])\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results_df = results_df.append({\n",
    "        'Model Name': model_name,\n",
    "        'Validation MSE': mse_val,\n",
    "        'Validation MAE Month': mae_val_week,\n",
    "        'Validation MSE Month': mse_val_week,\n",
    "        'Test MSE': mse_test,\n",
    "        'Test MAE': mae_test,\n",
    "        'Test MSE Month': mse_test_month\n",
    "        \n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    # Save all results to Excel\n",
    "    results_df.to_excel(os.path.join(model_dir, 'results_summary.xlsx'), index=False)\n",
    "\n",
    "print('Results and plots saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360eddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(r\".\\models\\models_saved\\model_9_hidden_dims_[128_64]_dense_units_[64_32_16]_dropout_0.5_lr_0.0001_batch_4_epochs_200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5555e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mse = mean_squared_error(target_scaler.inverse_transform(y_val.reshape(-1,1)),\n",
    "                             target_scaler.inverse_transform(y_val_pred.reshape(-1,1)))\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "\n",
    "val_mae = mean_absolute_error(target_scaler.inverse_transform(y_val.reshape(-1,1)),\n",
    "                             target_scaler.inverse_transform(y_val_pred.reshape(-1,1)))\n",
    "print(\"Validation MAE:\", val_mae)\n",
    "\n",
    "\n",
    "# Test plotting\n",
    "X_test = prepare_data_for_predictions(train_df, val_df,test_df,n_lags=sequence_length)  # Adjusted to return only X_test\n",
    "\n",
    "prediction_days = 80\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "preds = pd.DataFrame(target_scaler.inverse_transform(predictions_test),columns=['Prediction'], index = test_df.index)\n",
    "real_test_values = test_df['Close']\n",
    "\n",
    "test_valuations = pd.DataFrame(index = test_df.index[:prediction_days])\n",
    "test_valuations['Prediction'] = preds[:prediction_days]\n",
    "test_valuations['Close'] = real_test_values[:prediction_days]\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_test = mean_squared_error(test_valuations['Close'], test_valuations['Prediction'])\n",
    "\n",
    "mae_test = mean_absolute_error(test_valuations['Close'], test_valuations['Prediction'])\n",
    "\n",
    "\n",
    "\n",
    "# Save validation valuations MSE\n",
    "mse_test_month = mean_squared_error(test_valuations['Close'],\n",
    "                                  test_valuations['Prediction'])\n",
    "rmse_test = np.sqrt(mse_test_month)\n",
    "\n",
    "\n",
    "print(f'Test MSE: {mse_test_month}')\n",
    "print(f'Test RMSE: {rmse_test}')\n",
    "print(f'Test MAE: {mae_test}')\n",
    "\n",
    "# Save predictions plot for validation set\n",
    "future_days = 30\n",
    "\n",
    "prediction_type = 'Test'\n",
    "model_name = 'best_model_hidden_dims_[128_64]_dense_units_[64_32_16]_dropout_0.5_lr_0.0001_batch_4_epochs_200'\n",
    "periods= 30\n",
    "dates = pd.date_range(start= test_df.index[0], periods=future_days)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dates, y_test[:future_days], label='Actual Values', color='blue', marker='o')\n",
    "plt.plot(dates, target_scaler.inverse_transform(predictions_test[:future_days]), label='Predicted Values', color='orange', marker='x')\n",
    "\n",
    "# Formatting the x-axis\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=1))\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(f'{model_name} - {prediction_type} - Predictions vs Actual Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Calculate Mean Squared Error for validation set target_scaler.inverse_transform()\n",
    "mse_val = mean_squared_error(target_scaler.inverse_transform(y_val.reshape(-1,1)),\n",
    "                             target_scaler.inverse_transform(y_val_pred.reshape(-1,1)))\n",
    "\n",
    "# Prepare for test predictions\n",
    "prediction_days = 80\n",
    "start_index = len(val_df) - sequence_length\n",
    "preds_val = pd.DataFrame(target_scaler.inverse_transform(y_val_pred), columns=['Prediction_val'], index= val_df.iloc[-start_index:].index)\n",
    "\n",
    "validation_valuations = pd.DataFrame(index = preds_val.iloc[:prediction_days].index)\n",
    "\n",
    "validation_valuations['Prediction'] = preds_val['Prediction_val'][:prediction_days] \n",
    "validation_valuations['Close'] = target_scaler.inverse_transform(y_val[:prediction_days].reshape(-1,1))\n",
    "\n",
    "# Save validation valuations MSE\n",
    "mse_val_week = mean_squared_error(validation_valuations['Close'],\n",
    "                                 validation_valuations['Prediction'])\n",
    "\n",
    "# Save validation valuations MSE\n",
    "mae_val_week = mean_absolute_error(validation_valuations['Close'],\n",
    "                                 validation_valuations['Prediction'])\n",
    "\n",
    "print(f'Mean Squared Error for Validation Predictions: {mse_val_week}')\n",
    "\n",
    "\n",
    "# Test plotting\n",
    "X_test = prepare_data_for_predictions(train_df, val_df,test_df,n_lags=sequence_length)  # Adjusted to return only X_test\n",
    "\n",
    "prediction_days = 80\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "preds = pd.DataFrame(target_scaler.inverse_transform(predictions_test),columns=['Prediction'], index = test_df.index)\n",
    "real_test_values = test_df['Close']\n",
    "\n",
    "test_valuations = pd.DataFrame(index = test_df.index[:prediction_days])\n",
    "test_valuations['Prediction'] = preds[:prediction_days]\n",
    "test_valuations['Close'] = real_test_values[:prediction_days]\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_test = mean_squared_error(test_valuations['Close'], test_valuations['Prediction'])\n",
    "\n",
    "mae_test = mean_absolute_error(test_valuations['Close'], test_valuations['Prediction'])\n",
    "\n",
    "print(f'Mean Squared Error for Test Predictions: {mse_test}')\n",
    "\n",
    "save_predictions_plot(y_test[:future_days], target_scaler.inverse_transform(predictions_test[:future_days]), dates, model_name, model_dir, 'Test Set')\n",
    "\n",
    "    # Save validation valuations MSE\n",
    "mse_test_month = mean_squared_error(test_valuations['Close'],\n",
    "                                  test_valuations['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the validation set\n",
    "days_val = 14\n",
    "target_column= 'Close'\n",
    "plt.plot(val_df.iloc[-days_val:].index, val_df.iloc[-days_val:][target_column], label='Validation', color='orange')\n",
    "\n",
    "# Plot the test set\n",
    "plt.plot(test_df.iloc[:days_val].index, test_df.iloc[:days_val][target_column], label='Test', color='green')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(f'{target_column} over Time for Train, Validation, and Test Sets')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(target_column)\n",
    "\n",
    "# Add a legend to differentiate the sets\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
